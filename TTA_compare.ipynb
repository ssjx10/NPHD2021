{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22d86530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed : 20\n",
      "neg_listdir :  4000 pos_listdir :  4000\n",
      "len train :  7200 len val :  800\n",
      "batch_size 64\n",
      "TTA submit\n",
      "transform [Resize(always_apply=False, p=1, height=320, width=320, interpolation=1)]\n",
      "num_test : 13\n",
      "(800, 2)\n",
      "800\n",
      "f1: 0.9860583016476552\n",
      "acc: 0.98625\n",
      "avg_metric: 0.9863407185633358\n",
      "metric_list [0.98625, 1.0, 0.9725, 1.0, 0.9732360097323601, 0.9860583016476552]\n",
      "transform [Resize(always_apply=False, p=1, height=320, width=320, interpolation=1), VerticalFlip(always_apply=False, p=1)]\n",
      "num_test : 13\n",
      "(800, 2)\n",
      "800\n",
      "f1: 0.984848484848485\n",
      "acc: 0.985\n",
      "avg_metric: 0.9850394400184318\n",
      "metric_list [0.985, 0.995, 0.975, 0.9948979591836735, 0.9754901960784313, 0.984848484848485]\n",
      "transform [Resize(always_apply=False, p=1, height=320, width=320, interpolation=1), HorizontalFlip(always_apply=False, p=1)]\n",
      "num_test : 13\n",
      "(800, 2)\n",
      "800\n",
      "f1: 0.9860935524652339\n",
      "acc: 0.98625\n",
      "avg_metric: 0.9863060216595984\n",
      "metric_list [0.98625, 0.9975, 0.975, 0.9974424552429667, 0.9755501222493888, 0.9860935524652339]\n",
      "TTA submit2\n",
      "transform [Resize(always_apply=False, p=1, height=344, width=344, interpolation=1)]\n",
      "num_test : 13\n",
      "(800, 2)\n",
      "800\n",
      "f1: 0.9873737373737373\n",
      "acc: 0.9875\n",
      "avg_metric: 0.9875439822393605\n",
      "metric_list [0.9875, 0.9975, 0.9775, 0.9974489795918368, 0.9779411764705882, 0.9873737373737373]\n",
      "transform [Resize(always_apply=False, p=1, height=344, width=344, interpolation=1), HorizontalFlip(always_apply=False, p=1)]\n",
      "num_test : 13\n",
      "(800, 2)\n",
      "800\n",
      "f1: 0.9886506935687264\n",
      "acc: 0.98875\n",
      "avg_metric: 0.9887833574417701\n",
      "metric_list [0.98875, 0.9975, 0.98, 0.9974554707379135, 0.9803439803439803, 0.9886506935687264]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from Cyto_dataset import Cyto_train_dataset, Cyto_test_dataset\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from utils import *\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "import scipy as sp\n",
    "import time\n",
    "from albumentations.core.transforms_interface import DualTransform, ImageOnlyTransform\n",
    "\n",
    "import torchvision\n",
    "import time\n",
    "\n",
    "from classifier_utils_sw import submit_probs, out_label\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "seed=20\n",
    "seed_everything(seed)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "image_size = 320\n",
    "\n",
    "\n",
    "metric = ['acc', 'spe', 'sensi', 'pre', 'npv', 'f1']\n",
    "\n",
    "def eval(y_true, y_pred):\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    try: acc = (tp + tn) / (tp + tn + fp + fn)    \n",
    "    except: acc = 0\n",
    "    try: spe = tn / (tn + fp) # specificity\n",
    "    except: spe = 0\n",
    "    try: sensi = tp / (tp + fn) # sensitivity, recall    \n",
    "    except: sensi = 0\n",
    "    try: pre = tp / (fp + tp) # precision\n",
    "    except: pre = 0\n",
    "    try: npv = tn / (tn + fn)    \n",
    "    except: npv=0\n",
    "    try: f1 = 2 * (pre * sensi) / (pre + sensi)    \n",
    "    except: f1 = 0\n",
    " \n",
    "    return [acc, spe, sensi, pre, npv, f1]\n",
    "\n",
    "\n",
    "class Test_Rotation(DualTransform):\n",
    "    \"\"\"for tta\"\"\"\n",
    "    def __init__(self, angle, always_apply=False, p=0.5):\n",
    "        self.angle = angle\n",
    "        self.always_apply = always_apply\n",
    "        self.p = p\n",
    "\n",
    "        super(Test_Rotation, self).__init__(always_apply, p)\n",
    "        self.mask_value = None\n",
    "\n",
    "    def apply(self, image, **params):\n",
    "        # print(image.shape)\n",
    "        return sp.ndimage.rotate(image, self.angle, axes=(0,1), order=1,\n",
    "                reshape=False, mode='reflect')\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return ()\n",
    "\n",
    "class Test_Shift(DualTransform):\n",
    "    \"\"\"for tta\"\"\"\n",
    "    def __init__(self, shift, always_apply=False, p=0.5):\n",
    "        self.shift = shift + [0]\n",
    "         # 0(h) or 1(w)\n",
    "        self.always_apply = always_apply\n",
    "        self.p = p\n",
    "\n",
    "        super(Test_Shift, self).__init__(always_apply, p)\n",
    "        self.mask_value = None\n",
    "\n",
    "    def apply(self, image, **params):\n",
    "        # print(image.shape)\n",
    "        return sp.ndimage.shift(image, self.shift, order=1, mode='reflect')\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return ()\n",
    "\n",
    "\n",
    "scale = A.Resize(image_size, image_size)\n",
    "scale2 = A.Resize(344, 344)\n",
    "#rcrop = A.RandomCrop(width=256, height=256)\n",
    "shift_w = Test_Shift([0,10], p=1)\n",
    "shift_h = Test_Shift([10,0], p=1)\n",
    "rotate1 = Test_Rotation(5, p=1)\n",
    "rotate2 = Test_Rotation(-15, p=1)\n",
    "H_flip = A.HorizontalFlip(p=1)\n",
    "V_flip = A.VerticalFlip(p=1)\n",
    "\n",
    "normalize = A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "to_tensor = ToTensorV2()\n",
    "\n",
    "test_transform = A.Compose(\n",
    "        [\n",
    "            scale,\n",
    "            #scale_te,\n",
    "            normalize,\n",
    "            to_tensor\n",
    "        ])\n",
    "\n",
    "\n",
    "train_list, val_list = train_val_split('/home/ec2-user/dataset/b-trac-cyto/final', train_ratio=0.9)\n",
    "#train_list, val_list = train_val_split('/home/ec2-user/dataset/b-trac-cyto/practice', train_ratio=0.0)\n",
    "\n",
    "val_set = Cyto_train_dataset(val_list, transform=test_transform)\n",
    "\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "\n",
    "file_name = 'image_size_320_cos_full/14'\n",
    "\n",
    "model = models.resnet50(pretrained=False)\n",
    "model.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "model.load_state_dict(torch.load( '/home/ec2-user/workspace/check_point/' + file_name + '.pth'))\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "out_label = out_label(model, val_loader, device)\n",
    "#print(out_label(model, val_loader, device))\n",
    "\n",
    "\n",
    "make_csv = True\n",
    "save_dir = './result/'\n",
    "createFolder(save_dir)\n",
    "print('batch_size', batch_size)\n",
    "# transform_list = [None, V_flip, H_flip, rotate1, rotate2, shift_w, shift_h] # 0, 1, 2, 3, 4\n",
    "transform_list = [None, V_flip, H_flip]\n",
    "#transform_list = [rotate1, rotate2] \n",
    "# t_name_list = ['o', 'V', 'H','r15','r' ,'sw10', 'sh' ]\n",
    "t_name_list = ['o', 'V', 'H']\n",
    "t_name_len = len(t_name_list)\n",
    "cur_t_name = ''\n",
    "\n",
    "probs = 0 # 누적 probs\n",
    "print('TTA submit')\n",
    "for idx, new_transform in enumerate(transform_list):\n",
    "    if new_transform is None:\n",
    "        new_transform = [scale]\n",
    "    elif new_transform == 's2':\n",
    "        new_transform = [scale2]\n",
    "    else:\n",
    "        new_transform = [scale, new_transform]\n",
    "    cur_t_name += t_name_list[idx]\n",
    "    test_transform = A.Compose( new_transform +  [normalize, to_tensor] )\n",
    "    print('transform', new_transform)\n",
    "    test_set = Cyto_test_dataset(val_list, test_transform)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, num_workers=4)\n",
    "    print(f'num_test : {len(test_loader)}')\n",
    "\n",
    "    dic = submit_probs(model, test_loader, device)\n",
    "    probs += dic['probs']\n",
    "    print(len(probs))\n",
    "    pred = np.where(probs/(idx+1) > 0.5, 1, 0)\n",
    "    #pred = np.where(probs > 0.5, 1, 0)\n",
    "    metric_list = eval(out_label, pred)\n",
    "    avg_metric = sum(metric_list) / len(metric_list)\n",
    "    \n",
    "    print('f1:', f1_score(out_label, pred))\n",
    "    print('acc:', accuracy_score(out_label, pred))\n",
    "    print('avg_metric:', avg_metric)\n",
    "    print('metric_list',metric_list)\n",
    "\n",
    "\n",
    "print('TTA submit2')\n",
    "scale = A.Resize(344, 344)\n",
    "\n",
    "file_name2 = 'image_size_320_cos/14'\n",
    "\n",
    "model = models.resnet50(pretrained=False)\n",
    "model.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "model.load_state_dict(torch.load( '/home/ec2-user/workspace/check_point/' + file_name2 + '.pth'))\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "transform_list = [None, H_flip]\n",
    "t_name_list = ['o', 'H']\n",
    "\n",
    "for idx, new_transform in enumerate(transform_list):\n",
    "    if new_transform is None:\n",
    "        new_transform = [scale]\n",
    "    elif new_transform == 's2':\n",
    "        new_transform = [scale2]\n",
    "    else:\n",
    "        new_transform = [scale, new_transform]\n",
    "        \n",
    "    cur_t_name += t_name_list[idx]\n",
    "    test_transform = A.Compose( new_transform +  [normalize, to_tensor] )\n",
    "    print('transform', new_transform)\n",
    "    test_set = Cyto_test_dataset(val_list, test_transform)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, num_workers=4)\n",
    "    print(f'num_test : {len(test_loader)}')\n",
    "\n",
    "    dic = submit_probs(model, test_loader, device)\n",
    "    probs += dic['probs']\n",
    "    print(len(probs))\n",
    "    pred = np.where(probs/(idx+1+t_name_len) > 0.5, 1, 0)\n",
    "    #pred = np.where(probs > 0.5, 1, 0)\n",
    "    metric_list = eval(out_label, pred)\n",
    "    avg_metric = sum(metric_list) / len(metric_list)\n",
    "    \n",
    "    print('f1:', f1_score(out_label, pred))\n",
    "    print('acc:', accuracy_score(out_label, pred))\n",
    "    print('avg_metric:', avg_metric)\n",
    "    print('metric_list',metric_list)\n",
    "    \n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p37)",
   "language": "python",
   "name": "conda_pytorch_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
