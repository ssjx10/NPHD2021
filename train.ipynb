{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27a21fab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed : 20\n",
      "neg_listdir :  4000 pos_listdir :  4000\n",
      "len train :  7200 len val :  800\n",
      "num_train : 225, num_val : 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:691: FutureWarning: This class has been deprecated. Please use CoarseDropout\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_epoch:15, lr:1e-06, batch_size:32\n",
      "image_size_320_cos_full\n",
      "image_size_320_cos_full\n",
      "n_epoch:0\n",
      "[epoch_1, batch_100] loss: 0.6167233437299728, acc: 0.7053125, f1: 0.7079821527222225\n",
      "[epoch_1, batch_200] loss: 0.4776185804605484, acc: 0.8359375, f1: 0.8260694474621424\n",
      "perf_counter : 136.27989125601016\n",
      "process_time : 54.304402895\n",
      "train_loss: 0.5313847617308298 train_acc 0.7797222222222222 train_f1 0.7747798920761148 train_avg 0.7790784506953825\n",
      "valid_loss: 0.3481889677047729 valid_acc: 0.8775 valid_f1: 0.8703703703703702 valid_avg: 0.8778529606385411\n",
      "lr :  3.826891219729119e-06\n",
      "current epoch: 0\n",
      "0 save weight\n",
      "image_size_320_cos_full\n",
      "n_epoch:1\n",
      "[epoch_2, batch_100] loss: 0.3281785722076893, acc: 0.88125, f1: 0.8769720895566023\n",
      "[epoch_2, batch_200] loss: 0.2751482970267534, acc: 0.8934375, f1: 0.8882564997431391\n",
      "perf_counter : 138.32673852000153\n",
      "process_time : 54.38966916300001\n",
      "train_loss: 0.2969418840607007 train_acc 0.8879166666666667 train_f1 0.8845328373157819 train_avg 0.8877984248127434\n",
      "valid_loss: 0.2003273105621338 valid_acc: 0.92125 valid_f1: 0.9178617992177314 valid_avg: 0.9216475601914372\n",
      "lr :  9.029437251522862e-06\n",
      "current epoch: 1\n",
      "1 save weight\n",
      "image_size_320_cos_full\n",
      "n_epoch:2\n",
      "[epoch_3, batch_100] loss: 0.21944402873516083, acc: 0.910625, f1: 0.9097378921326867\n",
      "[epoch_3, batch_200] loss: 0.19876222733408214, acc: 0.9246875, f1: 0.9213600126003105\n",
      "perf_counter : 137.15623894397868\n",
      "process_time : 53.828647704000005\n",
      "train_loss: 0.20721841330329577 train_acc 0.9173611111111111 train_f1 0.9165380838827325 train_avg 0.9172780740635823\n",
      "valid_loss: 0.13949297055602072 valid_acc: 0.94375 valid_f1: 0.9420849420849421 valid_avg: 0.9439631621101724\n",
      "lr :  1.6815597623237844e-05\n",
      "current epoch: 2\n",
      "2 save weight\n",
      "image_size_320_cos_full\n",
      "n_epoch:3\n",
      "[epoch_4, batch_100] loss: 0.16179631493985652, acc: 0.935, f1: 0.9343698751551187\n",
      "[epoch_4, batch_200] loss: 0.15184110291302205, acc: 0.945625, f1: 0.9432482904003485\n",
      "perf_counter : 138.75826096197125\n",
      "process_time : 53.943794532\n",
      "train_loss: 0.155149756471316 train_acc 0.9411111111111111 train_f1 0.9406827084499161 train_avg 0.9410703951675042\n",
      "valid_loss: 0.09784476276487113 valid_acc: 0.965 valid_f1: 0.9644670050761421 valid_avg: 0.9650507931757871\n",
      "lr :  2.6000000000000002e-05\n",
      "current epoch: 3\n",
      "3 save weight\n",
      "image_size_320_cos_full\n",
      "n_epoch:4\n",
      "[epoch_5, batch_100] loss: 0.1367091554403305, acc: 0.948125, f1: 0.9477807116214803\n",
      "[epoch_5, batch_200] loss: 0.12201044401153922, acc: 0.95375, f1: 0.9506922191716142\n",
      "perf_counter : 136.6664968749974\n",
      "process_time : 53.944903468999996\n",
      "train_loss: 0.12724751392172443 train_acc 0.9516666666666667 train_f1 0.9514237855946398 train_avg 0.9516412435492573\n",
      "valid_loss: 0.06425503931939602 valid_acc: 0.9775 valid_f1: 0.9772727272727273 valid_avg: 0.9775258133556454\n",
      "lr :  3.518440237676215e-05\n",
      "current epoch: 4\n",
      "4 save weight\n",
      "image_size_320_cos_full\n",
      "n_epoch:5\n",
      "[epoch_6, batch_100] loss: 0.1130028641782701, acc: 0.95875, f1: 0.9581265052548862\n",
      "[epoch_6, batch_200] loss: 0.1095663041062653, acc: 0.955625, f1: 0.9537033510379598\n",
      "perf_counter : 139.90741086401977\n",
      "process_time : 53.95820164899999\n",
      "train_loss: 0.10826323681407504 train_acc 0.9595833333333333 train_f1 0.9593972373377982 train_avg 0.9595651910045581\n",
      "valid_loss: 0.07435937579721212 valid_acc: 0.97375 valid_f1: 0.9731113956466069 valid_avg: 0.9740006711388703\n",
      "lr :  4.297056274847714e-05\n",
      "current epoch: 5\n",
      "image_size_320_cos_full\n",
      "n_epoch:6\n",
      "[epoch_7, batch_100] loss: 0.09715282812714576, acc: 0.960625, f1: 0.9605596152068344\n",
      "[epoch_7, batch_200] loss: 0.08750894371420145, acc: 0.97, f1: 0.9690308116953839\n",
      "perf_counter : 136.60320172697539\n",
      "process_time : 53.81170154800003\n",
      "train_loss: 0.08890918820475538 train_acc 0.9669444444444445 train_f1 0.9667968750000001 train_avg 0.9669321486341033\n",
      "valid_loss: 0.04626024827361107 valid_acc: 0.98 valid_f1: 0.9797979797979798 valid_avg: 0.9800303555765741\n",
      "lr :  4.8173108780270884e-05\n",
      "current epoch: 6\n",
      "6 save weight\n",
      "image_size_320_cos_full\n",
      "n_epoch:7\n",
      "[epoch_8, batch_100] loss: 0.09119269997347146, acc: 0.9671875, f1: 0.966533223038419\n",
      "[epoch_8, batch_200] loss: 0.08542604471091181, acc: 0.9675, f1: 0.9655852844888274\n",
      "perf_counter : 138.44975818501553\n",
      "process_time : 53.57538074099995\n",
      "train_loss: 0.0882831025744478 train_acc 0.9669444444444445 train_f1 0.9668800445310325 train_avg 0.9669360650991856\n",
      "valid_loss: 0.04569889173842966 valid_acc: 0.98 valid_f1: 0.9798994974874371 valid_avg: 0.9799992511813995\n",
      "lr :  5e-05\n",
      "current epoch: 7\n",
      "image_size_320_cos_full\n",
      "n_epoch:8\n",
      "[epoch_9, batch_100] loss: 0.0683825013646856, acc: 0.974375, f1: 0.9733474587658405\n",
      "[epoch_9, batch_200] loss: 0.07321510675363242, acc: 0.9734375, f1: 0.9721694709867466\n",
      "perf_counter : 138.66546105698217\n",
      "process_time : 53.830747979999956\n",
      "train_loss: 0.07185439256744253 train_acc 0.9734722222222222 train_f1 0.9734316316594798 train_avg 0.9734669306539919\n",
      "valid_loss: 0.14690926066599785 valid_acc: 0.94875 valid_f1: 0.94640522875817 valid_avg: 0.9495132881394831\n",
      "lr :  4.972077177254559e-05\n",
      "current epoch: 8\n",
      "image_size_320_cos_full\n",
      "n_epoch:9\n",
      "[epoch_10, batch_100] loss: 0.06036174800246954, acc: 0.9803125, f1: 0.9802897604388722\n",
      "[epoch_10, batch_200] loss: 0.051716126706451176, acc: 0.9796875, f1: 0.9779875703563207\n",
      "perf_counter : 137.88750449300278\n",
      "process_time : 53.71943649500008\n",
      "train_loss: 0.0565359896969878 train_acc 0.9788888888888889 train_f1 0.9788654060066742 train_avg 0.9788857633735466\n",
      "valid_loss: 0.04263998766313307 valid_acc: 0.9825 valid_f1: 0.9823232323232323 valid_avg: 0.9825348977975029\n",
      "lr :  4.888932458737294e-05\n",
      "current epoch: 9\n",
      "9 save weight\n",
      "image_size_320_cos_full\n",
      "n_epoch:10\n",
      "[epoch_11, batch_100] loss: 0.05064526061760262, acc: 0.98375, f1: 0.9833548909357606\n",
      "[epoch_11, batch_200] loss: 0.05276492801262066, acc: 0.9834375, f1: 0.9831369307482266\n",
      "perf_counter : 136.81493537401548\n",
      "process_time : 53.76063181699999\n",
      "train_loss: 0.0515840671190785 train_acc 0.98375 train_f1 0.9837024655244464 train_avg 0.9837475647532905\n",
      "valid_loss: 0.05915748669300228 valid_acc: 0.98375 valid_f1: 0.9836065573770492 valid_avg: 0.9837754908367943\n",
      "lr :  4.7524231600673685e-05\n",
      "current epoch: 10\n",
      "10 save weight\n",
      "image_size_320_cos_full\n",
      "n_epoch:11\n",
      "[epoch_12, batch_100] loss: 0.04327984397765249, acc: 0.985, f1: 0.9847009781406826\n",
      "[epoch_12, batch_200] loss: 0.05270506237167865, acc: 0.9815625, f1: 0.9807638306500954\n",
      "perf_counter : 139.12881423794897\n",
      "process_time : 53.92323108200003\n",
      "train_loss: 0.04593907095802327 train_acc 0.9838888888888889 train_f1 0.9839023036358591 train_avg 0.9838915727265628\n",
      "valid_loss: 0.06442152966745197 valid_acc: 0.97375 valid_f1: 0.973248407643312 valid_avg: 0.9738887843125336\n",
      "lr :  4.565598673402244e-05\n",
      "current epoch: 11\n",
      "image_size_320_cos_full\n",
      "n_epoch:12\n",
      "[epoch_13, batch_100] loss: 0.040021411525085565, acc: 0.98625, f1: 0.9862330068526428\n",
      "[epoch_13, batch_200] loss: 0.04642352546914481, acc: 0.9834375, f1: 0.9826341700085237\n",
      "perf_counter : 140.23652849899372\n",
      "process_time : 53.95260151799994\n",
      "train_loss: 0.04328437013137672 train_acc 0.9845833333333334 train_f1 0.9845382365231926 train_avg 0.9845813138166748\n",
      "valid_loss: 0.029401190478820352 valid_acc: 0.98625 valid_f1: 0.9862671660424469 valid_avg: 0.9862538740342394\n",
      "lr :  4.3326323490558476e-05\n",
      "current epoch: 12\n",
      "12 save weight\n",
      "image_size_320_cos_full\n",
      "n_epoch:13\n",
      "[epoch_14, batch_100] loss: 0.03689243102679029, acc: 0.985625, f1: 0.9857374163573159\n",
      "[epoch_14, batch_200] loss: 0.04751086380565539, acc: 0.9828125, f1: 0.9823169945873588\n",
      "perf_counter : 139.38082640897483\n",
      "process_time : 54.65486862699993\n",
      "train_loss: 0.043270257973215646 train_acc 0.98375 train_f1 0.983729662077597 train_avg 0.9837476181650651\n",
      "valid_loss: 0.06201832252787426 valid_acc: 0.9825 valid_f1: 0.982367758186398 valid_avg: 0.982514155341753\n",
      "lr :  4.0587282697488157e-05\n",
      "current epoch: 13\n",
      "image_size_320_cos_full\n",
      "n_epoch:14\n",
      "[epoch_15, batch_100] loss: 0.03650224876269931, acc: 0.985, f1: 0.984596969105916\n",
      "[epoch_15, batch_200] loss: 0.04283223528182134, acc: 0.98375, f1: 0.9831206939019426\n",
      "perf_counter : 135.9004846359603\n",
      "process_time : 53.92042364100007\n",
      "train_loss: 0.03831601532344293 train_acc 0.9851388888888889 train_f1 0.9851037171098428 train_avg 0.9851366331053814\n",
      "valid_loss: 0.046002880204468966 valid_acc: 0.98625 valid_f1: 0.9860583016476552 valid_avg: 0.9863407185633358\n",
      "lr :  3.750005e-05\n",
      "current epoch: 14\n",
      "14 save weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "# print(os.getcwd())\n",
    "import random\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from Cyto_dataset import *\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from utils import *\n",
    "from classifier_utils import *\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import time\n",
    "\n",
    "from classifier_utils_sw import train,test\n",
    "#import argparse\n",
    "\n",
    "seed=20\n",
    "seed_everything(seed)\n",
    "\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='Arg')\n",
    "# parser.add_argument('--trial', type=str)\n",
    "# parser.add_argument('--image_size', type=int, default=456)\n",
    "# parser.add_argument('--batch_size', type=int, default=8)\n",
    "# parser.add_argument('--n_epochs', type=int, default=16)\n",
    "# parser.add_argument('--lr', type=float, default=1e-5)\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "n_cls = 2\n",
    "    \n",
    "ben_prepro = False\n",
    "# image_size = (args.image_size, args.image_size)\n",
    "# batch_size = args.batch_size\n",
    "# n_epochs = args.n_epochs\n",
    "# lr = args.lr\n",
    "Full_setting= True\n",
    "# lr = 2.5e-5\n",
    "image_size = 320\n",
    "batch_size = 32\n",
    "n_epochs = 15\n",
    "lr = 1e-6\n",
    "trial ='image_size_320_cos_full'\n",
    " \n",
    "\n",
    "#scale_te = A.Resize(256, 256)\n",
    "scale = A.Resize(image_size, image_size)\n",
    "#rcrop = A.RandomCrop(width=256, height=256)\n",
    "rotate = A.Rotate(limit=15)\n",
    "H_flip = A.HorizontalFlip(p=0.5)\n",
    "V_flip = A.VerticalFlip(p=0.5)\n",
    "cutout = A.Cutout(num_holes=8, max_h_size=8, max_w_size=8, p=0.5)\n",
    "elastic = A.ElasticTransform(p=0.5)\n",
    "RBC = A.RandomBrightnessContrast(p=0.5)\n",
    "blur = A.Blur(blur_limit=24, p=0.5)\n",
    "HSV = A.HueSaturationValue(p=0.5)\n",
    "ssr = A.ShiftScaleRotate(rotate_limit=30, p=0.5)\n",
    "\n",
    "normalize = A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "to_tensor = ToTensorV2()\n",
    "\n",
    "train_transform = A.Compose(\n",
    "        [\n",
    "            scale,\n",
    "            #rcrop,\n",
    "            #rotate,\n",
    "            H_flip,          \n",
    "            V_flip,\n",
    "            ssr,\n",
    "            elastic,\n",
    "            #blur,\n",
    "            cutout,\n",
    "            #RBC,\n",
    "\n",
    "            normalize,\n",
    "            to_tensor\n",
    "        ])\n",
    "\n",
    "test_transform = A.Compose(\n",
    "        [\n",
    "            scale,\n",
    "            #scale_te,\n",
    "            normalize,\n",
    "            to_tensor\n",
    "        ])\n",
    "\n",
    "\n",
    "train_list, val_list = train_val_split('/home/ec2-user/dataset/b-trac-cyto/final', train_ratio=0.9)\n",
    "#train_fold, val_fold = fold5_split('/home/ec2-user/dataset/b-trac-cyto/final')\n",
    "\n",
    "\n",
    "\n",
    "train_set = Cyto_train_dataset(train_list, transform=train_transform)\n",
    "val_set = Cyto_train_dataset(val_list, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=4)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "\n",
    "\n",
    "print(f'num_train : {len(train_loader)}, num_val : {len(val_loader)}')\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "#model.load_state_dict(torch.load('./weights/pretrain_model.pth'))\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "weight_decay = 1e-5\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay )\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.00005, \n",
    "                                                steps_per_epoch=2, epochs=15,anneal_strategy='cos')\n",
    "print(f'n_epoch:{n_epochs}, lr:{lr}, batch_size:{batch_size}')\n",
    "\n",
    "\n",
    "\n",
    "createFolder('./check_point/'+trial)\n",
    "\n",
    "print(trial)\n",
    "\n",
    "best_model, best_epoch = train(model, n_cls, n_epochs, train_loader, val_loader, criterion, optimizer, scheduler, trial, device)\n",
    "\n",
    "#torch.save(best_model.state_dict(), './check_point/final_model.pth')\n",
    "\n",
    "\n",
    "print(\"done\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p37)",
   "language": "python",
   "name": "conda_pytorch_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
